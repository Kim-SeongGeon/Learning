# Part 1. 수학의 기초

## Chapter 2. SLAM에 대한 첫 번쨰 지식

### 2.1 소개: 순무 로봇

이 책에서 소개하는 순무 로봇은 바퀴를 가지고 있기 때문에 움직일 수 있지만, 효과적인 경로 계획과 탐색 시스템 및 제어가 없다면 순무는 행동의 목표가 어디인지 알지 못한 채 맹목적으로 주변을 방황하는 것 외에는 아무것도 할 수 없게 된다. 이를 피하고자 먼저 주변 환경을 인식해야 하는데 로봇이 인간과 유사하다는 점에 착안하여 순무의 머리에 카메라를 설치했다. 순무가 방을 탐험할 수 있도록 하려면 최소한 다음의 두 가지를 알아야 한다.

1. 나는 지금 어디에 있을까? - Localization, 위치 추정
2. 내 주변 환경은 어떤 모습일까? - Map Building, 지도 작성

위치 추정과 지도 작성은 인지(perception)라는 영역의 각각 내부적 및 외부적 방향으로 볼 수 있다. 완전한 자율 이동 로봇으로서 순무는 내부적으로는 자신의 상태(즉, 위치)와 동시에 외부적으로는 주변 환경(즉, 지도)을 이해해야 한다.

레이저 센서, 카메라, 휠 엔코더(Wheel Encoder), 관성 측정 장치(Inertial Measurement Unit, IMU)와 같은 로봇 본체에 운반되는 센서는 일반적으로 직접 위치 데이터가 아닌 간접 물리적 양을 측정한다. 예를 들어, 휠 엔코더는 바퀴의 회전 각도를 측정하고 IMU는 움직임의 각속도와 가속도를 측정하며 카메라와 레이저 센서는 외부 환경을 이미지나 포인트 클라우드와 같은 특정 형태로 관측한다.

Visual SLAM이 이 책의 주제이므로, 우리는 특히 순무의 눈(즉, 카메라)이 무엇을 할 수 있는지에 대해 관심이 있다. SLAM에 사용되는 카메라는 우리가 일반적으로 보는 SLR(Single Lens Reflex) 카메라와 동일하지 않다. 

작동 방식에 따라 카메라는 단안 카메라, 스테레오 카메라 및 RGB-D 카메라의 세가지 범주로 나눌 수 있다. 단안 카메라는 직관적으로 알 수 있듯이 하나의 카메라를 가지고 있으며 스테레오 카메라는 두 개의 카메라를 가지고 있다. 반면, RGB-D 카메라의 원리는 조금 더 복잡한데 컬러 사진을 캡처할 수 있을 뿐만 아니라 픽셀별로 카메라로부터 캡처된 대상까지의 거리를 측정할 수 있다. 그래서 RGB-D 카메라는 깊이 카메라라고도 불린다. 

### 2.1.1 단안 카메라

SLAM을 위해 하나의 카메라만 사용하는 것을 단안 SLAM(Monocular SLAM)이라고 한다. 우리는 단안 카메라의 데이터를 본 적이 있다: 그렇다, 물론 사진이다. 사진은 기본적으로 장면(Scene)이 카메라 이미징 평면에 남긴 투영을 촬영하는 것이다. 그것은 3차원 세계를 2차원 이미지의 형태로 기록하는 것이다. 그렇다면 분명히 이 사진을 찍는 프로세스는 깊이(또는 거리)라고 하는 장면의 차원 중 하나를 잃어버리게 되는 것이다. 단안 카메라에서는 장면의 피사체와 카메라 사이의 거리를 단일 이미지로는 얻을 수 없다. 단안 카메라로 촬영한 영상은 3차원 공간의 2차원 투영일 뿐이기 때문에 3차원 구조를 복원하려면 카메라의 시야각을 바꿔야 한다. 단안 SLAM에서도 동일한 원리가 적용된다. 단안 SLAM에 의해 추정된 궤적 및 지도가 소위 스케일(Scale)이라는 요소에 의해 실제 궤적 및 지도와 다를 것임을 의미한다. 단안 SLAM은 이미지만으로는 실제 스케일을 결정할 수 없으며 이를 스케일 모호성(Scale Ambiguity)이라고도 한다.

단안 SLAM에서 깊이 정보는 이동 후에만 계산할 수 있고 실제 축척을 결정할 수 없으므로, 단안 SLAM을 실제 세계에 적용하는 것은 큰 어려움이 있었다. 위에서도 언급했듯이 근본 원인은 하나의 이미지에서 깊이를 결정할 수 없기 때문이다. 그래서 사람들은 이 깊이 정보를 얻기 위해 스테레오(양안 또는 쌍 안) 카메라와 RGB-D 카메라를 사용하기 시작했다.

### 2.1.2 스테레오 카메라 및 RGB-D 카메라

스테레오 카메라와 RGB-D 카메라를 사용하는 목적은 물체와 카메라 사이의 거리를 측정하여 단안 카메라가 거리를 알 수 없다는 단점을 극복하는 것이다. 거리가 알려지면 스케일 불확실성을 제거하면서 장면의 3D 구조를 복구할 수 있다. 둘 다 거리를 측정하는 데 사용되지만, 스테레오 카메라와 RGB-D 카메라는 거리를 측정하는 원리가 다르다. 스테레오 카메라는 두 대의 단안 카메라로 구성된 양안 또는 쌍 안 카메라라고도 하며 이 두 카메라 사이의 거리인 기준선(Baseline)이 알고 있는 값이다. 우리는 이 두 카메라 사이의 거리를 사용하여 사람의 눈과 매우 유사하게 각 픽셀의 공간적 위치를 추정한다. 

스테레오 카메라는 각 픽셀의 깊이를(신뢰하기 힘들 정도로라도) 추정하기 위해 많은 계산을 해야 하며 그 성능은 인간보다 정말 서툴다고 말할 정도이다. 스테레오 카메라로 측정한 깊이 범위는 두 카메라 사이의 거리인 기준선의 길이와 관련이 있다. 기준선의 길이가 길수록 물체를 더 멀리 측정할 수 있으므로 무인 자동차의 양안 카메라는 일반적으로 꽤 클 수밖에 없다. 스테레오 카메라의 거리 추정은 좌안과 우안의 영상을 비교하여 얻어지며, 다른 센싱 장치에 의존하지 않으므로 실내외에 모두 적용할 수 있다. 양안 또는 다 안 카메라의 단점은 구성 및 보정이 복잡하고 깊이 범위와 정확도가 양안 기준선 및 해상도에 의해 제한되며 시차 계산에 컴퓨팅 리소스가 많이 소모된다는 점이다. 그래서 일반적으로 실시간으로 깊이 지도를 생성하기 위해서는 GPU나 FPGA를 이용한 가속이 필요하다.

RGB-D 카메라(또는 깊이 카메라라고도 하는데 이 책에서 주로 RGB-D 카메라라는 이름을 사용)의 가장 큰 특징은 적외선 또는 ToF(Time-of-Flight)의 원리를 이용하여 물체와의 거리를 계산한다는 것이다. 원리는 레이저 센서와 마찬가지로 물체에 능동적으로 빛을 방출하고 반환된 빛을 수신하여 물체와 카메라 사이의 거리를 측정하는 것이다. 스테레오 카메라처럼 소프트웨어 게산으로 해결되는 것이 아니라 물리적인 측정 방식으로 해결하기 때문에 스테레오 카메라에 비해 많은 컴퓨팅 자원을 절약할 수 있다. 그러나 대부분의 RGB-D 카메라는 여전히 좁은 측정 범위, 높은 노이즈, 작은 화각(FoV, Field of View), 태양광의 간섭을 받기 쉬운 점, 그리고 투명한 물체는 측정이 불가한 점 등 많은 문제를 가지고 있으므로 SLAM 목적으로는 실외에서 사용이 제한되는 측면이 있어 주로 실내에서만 사용된다.

### 2.2 전형적인 Visual SLAM 프레임워크

↓ 전형적인 Visual SLAM 프레임워크 이미지

<img src="Images/Typical Visual SLAM Framework.png" width="500"/>

전체 Visual SLAM 프로세스에는 다음 단계가 포함된다.

1. 센서 정보를 읽는다. Visual SLAM에서는 주로 카메라 이미지 정보를 읽고 전처리를 한다. 로봇의 경우 모터 엔코더 및 관성 센서와 같은 정보를 읽고 동기화할 수도 있다.

2. Visual Odometry는 시각적 주행거리 측정이라고도 하는데 인접한 이미지 사이의 카메라 움직임을 추정하고 대강의 로컬 맵을 생성하는 것이며 프론트엔드(Frontend)라고도 한다.

3. Filters Optimization은 비선형 최적화 과정으로 서로 다른 시간에 VO로 측정한 카메라 포즈와 루프 백 감지 정보를 받아들이고 최적화하여 전역적으로 일관된 궤적과 지도를 얻는 것을 말한다. VO 뒤에 연결되기 때문에 백엔드(Backend)라고도 한다.

4. Loop Closing은 루프 백 감지라고 하며 로봇이 이전에 도달했던 위치에 다시 왔는지 여부를 결정한다. 루프 백이 감지되면 더 나은 최적화 처리를 위해 정보를 백엔드에 제공한다.

5. Reconstruction은 매핑 즉, 맵을 만드는 과정으로 추정된 카메라의 궤적을 기반으로 임무 요구사항에 해당하는 맵을 구축하는 것을 말한다.
