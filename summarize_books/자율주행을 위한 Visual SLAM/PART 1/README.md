# Part 1. 수학의 기초

## Chapter 2. SLAM에 대한 첫 번쨰 지식

### 2.1 소개: 순무 로봇

이 책에서 소개하는 순무 로봇은 바퀴를 가지고 있기 때문에 움직일 수 있지만, 효과적인 경로 계획과 탐색 시스템 및 제어가 없다면 순무는 행동의 목표가 어디인지 알지 못한 채 맹목적으로 주변을 방황하는 것 외에는 아무것도 할 수 없게 된다. 이를 피하고자 먼저 주변 환경을 인식해야 하는데 로봇이 인간과 유사하다는 점에 착안하여 순무의 머리에 카메라를 설치했다. 순무가 방을 탐험할 수 있도록 하려면 최소한 다음의 두 가지를 알아야 한다.

1. 나는 지금 어디에 있을까? - Localization, 위치 추정
2. 내 주변 환경은 어떤 모습일까? - Map Building, 지도 작성

위치 추정과 지도 작성은 인지(perception)라는 영역의 각각 내부적 및 외부적 방향으로 볼 수 있다. 완전한 자율 이동 로봇으로서 순무는 내부적으로는 자신의 상태(즉, 위치)와 동시에 외부적으로는 주변 환경(즉, 지도)을 이해해야 한다.

레이저 센서, 카메라, 휠 엔코더(Wheel Encoder), 관성 측정 장치(Inertial Measurement Unit, IMU)와 같은 로봇 본체에 운반되는 센서는 일반적으로 직접 위치 데이터가 아닌 간접 물리적 양을 측정한다. 예를 들어, 휠 엔코더는 바퀴의 회전 각도를 측정하고 IMU는 움직임의 각속도와 가속도를 측정하며 카메라와 레이저 센서는 외부 환경을 이미지나 포인트 클라우드와 같은 특정 형태로 관측한다.

Visual SLAM이 이 책의 주제이므로, 우리는 특히 순무의 눈(즉, 카메라)이 무엇을 할 수 있는지에 대해 관심이 있다. SLAM에 사용되는 카메라는 우리가 일반적으로 보는 SLR(Single Lens Reflex) 카메라와 동일하지 않다. 

작동 방식에 따라 카메라는 단안 카메라, 스테레오 카메라 및 RGB-D 카메라의 세가지 범주로 나눌 수 있다. 단안 카메라는 직관적으로 알 수 있듯이 하나의 카메라를 가지고 있으며 스테레오 카메라는 두 개의 카메라를 가지고 있다. 반면, RGB-D 카메라의 원리는 조금 더 복잡한데 컬러 사진을 캡처할 수 있을 뿐만 아니라 픽셀별로 카메라로부터 캡처된 대상까지의 거리를 측정할 수 있다. 그래서 RGB-D 카메라는 깊이 카메라라고도 불린다. 

### 2.1.1 단안 카메라

SLAM을 위해 하나의 카메라만 사용하는 것을 단안 SLAM(Monocular SLAM)이라고 한다. 우리는 단안 카메라의 데이터를 본 적이 있다: 그렇다, 물론 사진이다. 사진은 기본적으로 장면(Scene)이 카메라 이미징 평면에 남긴 투영을 촬영하는 것이다. 그것은 3차원 세계를 2차원 이미지의 형태로 기록하는 것이다. 그렇다면 분명히 이 사진을 찍는 프로세스는 깊이(또는 거리)라고 하는 장면의 차원 중 하나를 잃어버리게 되는 것이다. 단안 카메라에서는 장면의 피사체와 카메라 사이의 거리를 단일 이미지로는 얻을 수 없다. 단안 카메라로 촬영한 영상은 3차원 공간의 2차원 투영일 뿐이기 때문에 3차원 구조를 복원하려면 카메라의 시야각을 바꿔야 한다. 단안 SLAM에서도 동일한 원리가 적용된다. 단안 SLAM에 의해 추정된 궤적 및 지도가 소위 스케일(Scale)이라는 요소에 의해 실제 궤적 및 지도와 다를 것임을 의미한다. 단안 SLAM은 이미지만으로는 실제 스케일을 결정할 수 없으며 이를 스케일 모호성(Scale Ambiguity)이라고도 한다.

단안 SLAM에서 깊이 정보는 이동 후에만 계산할 수 있고 실제 축척을 결정할 수 없으므로, 단안 SLAM을 실제 세계에 적용하는 것은 큰 어려움이 있었다. 위에서도 언급했듯이 근본 원인은 하나의 이미지에서 깊이를 결정할 수 없기 때문이다. 그래서 사람들은 이 깊이 정보를 얻기 위해 스테레오(양안 또는 쌍 안) 카메라와 RGB-D 카메라를 사용하기 시작했다.
